{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu9s8Yl8hZOK",
        "outputId": "a7bc3069-46a7-4faa-a418-732c35479ce8"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK2tmNYiwcra"
      },
      "source": [
        "# 1.Import Liberaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSfDVO7MhZOM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Erad7Iw9hZOO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SQErPBehZOP",
        "outputId": "b5f2f84b-34b6-443f-996b-7552ed6d2309"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V4iYj4Owcre"
      },
      "source": [
        "# 2. Data Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTGkNMbshZOP"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_dir = 'Project7'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sRXLLcE4hZOR",
        "outputId": "43ff9de7-5dfa-4da8-f69b-624711e0b8b6"
      },
      "outputs": [],
      "source": [
        "os.listdir('project7')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63AizGAVhZOS"
      },
      "outputs": [],
      "source": [
        "image_exts = ['jpeg','jpg', 'bmp', 'png']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItdTY8vUwcre"
      },
      "source": [
        "# 3. Data Preprocessing and Showing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE25wZbRhZOT"
      },
      "outputs": [],
      "source": [
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('Image not in ext list {}'.format(image_path))\n",
        "                os.remove(image_path)\n",
        "        except Exception as e:\n",
        "            print('Issue with image {}'.format(image_path))\n",
        "            # os.remove(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2Nv2OMSghZOT",
        "outputId": "547619b8-0d28-451d-988e-ede8adf40cb4"
      },
      "outputs": [],
      "source": [
        "data = tf.keras.utils.image_dataset_from_directory('Project7')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdrh6n1shZOT"
      },
      "outputs": [],
      "source": [
        "data_iterator = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSjqDchJhZOU"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch = data_iterator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFSTygmOhZOU"
      },
      "outputs": [],
      "source": [
        "code= {\"Cardboard\" : 0 , \"Glass\" :1 , \"Paper\" : 2 ,\"Vegetation\" : 3 }\n",
        "\n",
        "def getcode(n):\n",
        "    for x,y in code.items() :\n",
        "        if n==y:\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "uyB02fHshZOV",
        "outputId": "7763cb6c-3a93-46fa-94ce-9632faa71ef6"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=6, figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:6]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])\n",
        "    ax[idx].title.set_text(getcode(batch[1][idx]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqPGiAFVhZOW"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = data.map(lambda x,y: (x/255, y))\n",
        "#normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lMl9DXXlhZOj",
        "outputId": "63c58f65-3533-4862-9dcb-b5963eb7bba4"
      },
      "outputs": [],
      "source": [
        "\n",
        "data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZMogVQChZOj"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.2)\n",
        "test_size = int(len(data)*.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPryK-m3hZOk"
      },
      "outputs": [],
      "source": [
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRcz9EEhZOk"
      },
      "source": [
        "# First Model using CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ccn4CXplhZOz",
        "outputId": "0d757a29-f0e4-4a5b-b4d4-21704cb65972"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2vSl_NahZOz"
      },
      "outputs": [],
      "source": [
        "model= Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxROHlX1hZOz"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(32, (3,3),  padding='same',activation='relu', input_shape=(256,256,3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.25))  # Dropout layer after pooling\n",
        "model.add(Conv2D(64, (3,3),padding='same' , activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.25))  # Another dropout layer\n",
        "model.add(Conv2D(128, (3,3),padding='same' , activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.25))  # And another one\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.1))  # Dropout before the final layers\n",
        "model.add(Dense(4, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebNqgQdAhZO0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6cqf58BhZO0",
        "outputId": "979e24d2-62bd-4fb5-c5ce-d103663153a0"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eyCiTCyhZO0"
      },
      "source": [
        "# Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ohPGUXkhZO1"
      },
      "outputs": [],
      "source": [
        "\n",
        "logdir='logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Okimc-vShZO1"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-mMZKxqhZO1",
        "outputId": "88c6f77d-325e-43a8-ebfc-57197678a7c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKJ1vQGIwcrz"
      },
      "source": [
        "# Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mbPJZp5Tsc-",
        "outputId": "1ee22d54-ebce-4f66-f2dc-78d0605bd3f7"
      },
      "outputs": [],
      "source": [
        "code = {\"Cardboard\": 0, \"Glass\": 1, \"Paper\": 2, \"Vegetation\": 3}\n",
        "\n",
        "def getcode(n):\n",
        "    for x, y in code.items():\n",
        "        if n == y:\n",
        "            return x\n",
        "\n",
        "num_images = 16  # Total number of images to display\n",
        "num_rows = 4\n",
        "num_cols = 4\n",
        "\n",
        "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
        "\n",
        "for i, batch in enumerate(test.take(1)):  # Assuming you want to take only one batch\n",
        "    images, labels = batch  # Assuming each batch contains images and labels\n",
        "    for j in range(num_images):  # Iterate over all images\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        predictions = model.predict(np.expand_dims(image, axis=0))\n",
        "        confidence = predictions[0][label.numpy()]\n",
        "\n",
        "        ax = axs[j // num_cols, j % num_cols]\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f\"Label: {getcode(label.numpy())}, Confidence: {confidence:.2f}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USNGWmMqhZO5",
        "outputId": "f5555079-4da6-4933-a312-4e7cb90a0a27"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test)\n",
        "\n",
        "print('Prediction Shape is {}'.format(y_pred.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuRRfovPhZO6"
      },
      "outputs": [],
      "source": [
        "# Convert the predictions to a TensorFlow Dataset\n",
        "predictions_dataset = tf.data.Dataset.from_tensor_slices(y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0EnbDnuhZO6",
        "outputId": "f11ec4d4-c7a0-4ce8-ed84-66d0e0cd89ba"
      },
      "outputs": [],
      "source": [
        "for prediction in predictions_dataset:\n",
        "    # Process each prediction\n",
        "    print(prediction.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M4RvMddyhZO7",
        "outputId": "296fcf45-99b2-4213-82f7-d11093f89da5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "folder_path = '1/Prediction'\n",
        "\n",
        "\n",
        "file_names = os.listdir(folder_path)\n",
        "\n",
        "\n",
        "file_names = file_names[:15]\n",
        "\n",
        "num_images = len(file_names)\n",
        "num_images_per_col = 5\n",
        "num_cols = 3\n",
        "num_rows = num_images_per_col\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
        "\n",
        "\n",
        "for i, file_name in enumerate(file_names):\n",
        "\n",
        "    img_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(256, 256))  # resize to smaller size\n",
        "\n",
        "\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "\n",
        "    img_array /= 255.0  # example normalization\n",
        "\n",
        "\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    confidence = predictions[0][predicted_class_index]\n",
        "\n",
        "\n",
        "    col = i // num_images_per_col\n",
        "    row = i % num_images_per_col\n",
        "    ax = axes[row, col]\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f\"{getcode(predicted_class_index)}\\nConfidence: {confidence:.2f}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb1xRgF0wcr6"
      },
      "source": [
        "# First Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z68gRwK1TsdA",
        "outputId": "9280c7b8-7c7b-4e75-c6d9-65a1ee3d51bd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yLDVYmyTsdB",
        "outputId": "5ab5f449-8e6d-4a97-c6a6-b430a03c3115"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jaGXgZzTsdG",
        "outputId": "624c649a-d157-4dad-d0b3-fbc49df6ed70"
      },
      "outputs": [],
      "source": [
        "\n",
        "ModelLoss, ModelAccuracy = model.evaluate(val)\n",
        "\n",
        "print('validation Loss is {}'.format(ModelLoss))\n",
        "print('validation Accuracy is {}'.format(ModelAccuracy ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lcFJmAITsdH",
        "outputId": "f2bfbf77-a3ed-4372-a6f0-85f04fb85b30"
      },
      "outputs": [],
      "source": [
        "ModelLoss, ModelAccuracy = model.evaluate(test)\n",
        "\n",
        "print('Test Loss is {}'.format(ModelLoss))\n",
        "print('Test Accuracy is {}'.format(ModelAccuracy ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxHxqtTMTsdH",
        "outputId": "42b61cb2-4e06-4bc8-b8d4-36bbc7fd20a0"
      },
      "outputs": [],
      "source": [
        "ModelLoss, ModelAccuracy = model.evaluate(train)\n",
        "\n",
        "print('Train Loss is {}'.format(ModelLoss))\n",
        "print('Train Accuracy is {}'.format(ModelAccuracy ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tS8HJmHhZO8",
        "outputId": "09e03c8e-75d2-40fa-9d92-c4a7df3831e1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Initialize lists to store the true and predicted labels\n",
        "y_true_values = []\n",
        "y_pred_values = []\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = model.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "\n",
        "    # Ensure y_pred has the same shape as y_flat\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "    y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "\n",
        "    # Store the true and predicted labels\n",
        "    y_true_values.extend(y_flat)\n",
        "    y_pred_values.extend(y_pred)\n",
        "print(classification_report(y_true_values, y_pred_values, target_names=code.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84JiQ9bshZO8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "pre=Precision()\n",
        "re=Recall()\n",
        "acc=Accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "8_OwFoSGhZO9",
        "outputId": "e0507327-3875-4477-a322-bc037466a5f9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize lists to store the metrics\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "accuracy_values = []\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = model.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "\n",
        "    # Ensure y_pred has the same shape as y_flat\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "    y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "\n",
        "    # Update the metrics\n",
        "    pre.update_state(y_flat, y_pred)\n",
        "    re.update_state(y_flat, y_pred)\n",
        "    acc.update_state(y_flat, y_pred)\n",
        "\n",
        "    # Store the current values of the metrics\n",
        "    precision_values.append(pre.result().numpy())\n",
        "    recall_values.append(re.result().numpy())\n",
        "    accuracy_values.append(acc.result().numpy())\n",
        "\n",
        "# Plot the metrics\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(precision_values, label='Precision')\n",
        "plt.plot(recall_values, label='Recall')\n",
        "plt.plot(accuracy_values, label='Accuracy')\n",
        "plt.xlabel('Batch number')\n",
        "plt.ylabel('Metric value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlovxubQhZO9",
        "outputId": "198f27bc-ca92-4f96-d574-9162073e8d68"
      },
      "outputs": [],
      "source": [
        "precision_values = []\n",
        "recall_values = []\n",
        "accuracy_values = []\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = model.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "pre.update_state(y_flat, y_pred)\n",
        "re.update_state(y_flat, y_pred)\n",
        "acc.update_state(y_flat, y_pred)\n",
        "precision_values.append(pre.result().numpy())\n",
        "recall_values.append(re.result().numpy())\n",
        "accuracy_values.append(acc.result().numpy())\n",
        "print('Precision:', pre.result().numpy())\n",
        "print('Recall:', re.result().numpy())\n",
        "print('Accuracy:', acc.result().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "pObsJACShZO-",
        "outputId": "595913a2-b60e-40e8-b2a8-7d308a7cc5f1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize lists to store the true and predicted labels\n",
        "y_true_values = []\n",
        "y_pred_values = []\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = model.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "\n",
        "    # Ensure y_pred has the same shape as y_flat\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "    y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "\n",
        "    # Store the true and predicted labels\n",
        "    y_true_values.extend(y_flat)\n",
        "    y_pred_values.extend(y_pred)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true_values, y_pred_values)\n",
        "\n",
        "# Create DataFrame from confusion matrix\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['Cardboard', 'Glass', 'Paper', 'Vegetation'],\n",
        "                     columns = ['Cardboard', 'Glass', 'Paper', 'Vegetation'])\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_df, annot=True)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actal Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Zy5Mj6wcr8"
      },
      "source": [
        "# Second Model using VGG16 for optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU_vbHHAwcr9"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "\n",
        "# Load pre-trained VGG16 model without the top (fully connected) layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Freeze the layers of the VGG16 model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create your custom model on top of the VGG16 base model\n",
        "modelV = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')  # Output layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvGgWTQOwcr9"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "modelV.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R39uaPJwcr9",
        "outputId": "c6904155-6669-4da6-8381-061a57e9714b"
      },
      "outputs": [],
      "source": [
        "modelV.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5eJXfLtwcr9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXcB0Lqbwcr-"
      },
      "outputs": [],
      "source": [
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU5WSYqVwcr-",
        "outputId": "b9f0a212-eda4-401b-eb2f-bf7628ec85e6"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "hist = modelV.fit(train, epochs=20, validation_data=val, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GglWMeb8TsdL"
      },
      "source": [
        "# Second Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "lsFVG_uDwcr-",
        "outputId": "a6e928c2-f938-49fb-bce8-eca298fc2dcb"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "U8xbYMBTwcr-",
        "outputId": "147041f0-3d5f-4cdd-b4d6-f8ddd30a18c0"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7qV0zF1wcr_",
        "outputId": "5761db89-4d68-4263-e88a-7a18c2fcbe80"
      },
      "outputs": [],
      "source": [
        "\n",
        "ModelLoss, ModelAccuracy = modelV.evaluate(val)\n",
        "\n",
        "print('validation Loss is {}'.format(ModelLoss))\n",
        "print('validation Accuracy is {}'.format(ModelAccuracy ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXzyGG-Zwcr_",
        "outputId": "530388aa-8c2b-4c0f-8387-91c3db0eaa21"
      },
      "outputs": [],
      "source": [
        "ModelLoss, ModelAccuracy = modelV.evaluate(test)\n",
        "print('Test Loss is {}'.format(ModelLoss))\n",
        "print('Test Accuracy is {}'.format(ModelAccuracy ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTN2eWFOwcsA",
        "outputId": "be457527-095d-42f5-e3ab-50732b4b03f9"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store the true and predicted labels\n",
        "y_true_values = []\n",
        "y_pred_values = []\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = modelV.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "\n",
        "    # Ensure y_pred has the same shape as y_flat\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "    y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "\n",
        "    # Store the true and predicted labels\n",
        "    y_true_values.extend(y_flat)\n",
        "    y_pred_values.extend(y_pred)\n",
        "print(classification_report(y_true_values, y_pred_values, target_names=code.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "jikChADowcsA",
        "outputId": "c881854c-75d7-4367-bb4b-dd4916c0b620"
      },
      "outputs": [],
      "source": [
        "pre = tf.keras.metrics.Precision()\n",
        "re = tf.keras.metrics.Recall()\n",
        "acc = tf.keras.metrics.Accuracy()\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "accuracy_values = []\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = modelV.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "\n",
        "    # Ensure y_pred has the same shape as y_flat\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "    y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "\n",
        "    # Update the metrics\n",
        "    pre.update_state(y_flat, y_pred)\n",
        "    re.update_state(y_flat, y_pred)\n",
        "    acc.update_state(y_flat, y_pred)\n",
        "\n",
        "    # Store the current values of the metrics\n",
        "    precision_values.append(pre.result().numpy())\n",
        "    recall_values.append(re.result().numpy())\n",
        "    accuracy_values.append(acc.result().numpy())\n",
        "\n",
        "# Plot the metrics\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(precision_values, label='Precision')\n",
        "plt.plot(recall_values, label='Recall')\n",
        "plt.plot(accuracy_values, label='Accuracy')\n",
        "plt.xlabel('Batch number')\n",
        "plt.ylabel('Metric value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSSLtQGjwcsA",
        "outputId": "23ca9196-0a1b-4bd2-f604-602e863ec62d"
      },
      "outputs": [],
      "source": [
        "precision_values = []\n",
        "recall_values = []\n",
        "accuracy_values = []\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = modelV.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "pre.update_state(y_flat, y_pred)\n",
        "re.update_state(y_flat, y_pred)\n",
        "acc.update_state(y_flat, y_pred)\n",
        "precision_values.append(pre.result().numpy())\n",
        "recall_values.append(re.result().numpy())\n",
        "accuracy_values.append(acc.result().numpy())\n",
        "print('Precision:', pre.result().numpy())\n",
        "print('Recall:', re.result().numpy())\n",
        "print('Accuracy:', acc.result().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "BkNy3D9SwcsA",
        "outputId": "486aa05c-4984-4962-95be-88cfeb9207ca"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "# Initialize lists to store the true and predicted labels\n",
        "y_true_values = []\n",
        "y_pred_values = []\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    x, y = batch\n",
        "    y_pred = modelV.predict(x)\n",
        "    y_flat = y.flatten() if len(y.shape) > 1 else y\n",
        "\n",
        "    # Ensure y_pred has the same shape as y_flat\n",
        "    y_pred = y_pred[:, :y_flat.shape[0]]  # Truncate y_pred to match the length of y_flat\n",
        "    y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to a 1D array\n",
        "\n",
        "    # Store the true and predicted labels\n",
        "    y_true_values.extend(y_flat)\n",
        "    y_pred_values.extend(y_pred)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true_values, y_pred_values)\n",
        "\n",
        "# Create DataFrame from confusion matrix\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['Cardboard', 'Glass', 'Paper', 'Vegetation'],\n",
        "                     columns = ['Cardboard', 'Glass', 'Paper', 'Vegetation'])\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_df, annot=True)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actal Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF7pKwYGTsdN"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5aVeRcDTsdO",
        "outputId": "7c3db7fc-8687-47b5-d68f-c4f8c24fbe9f"
      },
      "outputs": [],
      "source": [
        "code = {\"Cardboard\": 0, \"Glass\": 1, \"Paper\": 2, \"Vegetation\": 3}\n",
        "\n",
        "def getcode(n):\n",
        "    for x, y in code.items():\n",
        "        if n == y:\n",
        "            return x\n",
        "\n",
        "num_images = 16  # Total number of images to display\n",
        "num_rows = 4\n",
        "num_cols = 4\n",
        "\n",
        "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
        "\n",
        "for i, batch in enumerate(test.take(1)):  # Assuming you want to take only one batch\n",
        "    images, labels = batch  # Assuming each batch contains images and labels\n",
        "    for j in range(num_images):  # Iterate over all images\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        predictions = modelV.predict(np.expand_dims(image, axis=0))\n",
        "        confidence = predictions[0][label.numpy()]\n",
        "\n",
        "        ax = axs[j // num_cols, j % num_cols]\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f\"Label: {getcode(label.numpy())}, Confidence: {confidence:.2f}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI-4l4vmTsdO"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO0itp7ATsdO",
        "outputId": "9d0e0b8b-b883-426d-a3ac-8e7eff4bdc33"
      },
      "outputs": [],
      "source": [
        "\n",
        "folder_path = '1/prediction'\n",
        "\n",
        "# Get a list of all the file names in the folder\n",
        "file_names = os.listdir(folder_path)\n",
        "\n",
        "# Display only the first 15 images\n",
        "file_names = file_names[:15]\n",
        "\n",
        "# Calculate the number of rows and columns for subplots\n",
        "num_images = len(file_names)\n",
        "num_images_per_col = 5  # Number of images per column\n",
        "num_cols = 3  # Round up for columns\n",
        "num_rows = num_images_per_col  # Each column will have 5 images\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
        "\n",
        "# Iterate through each image file\n",
        "for i, file_name in enumerate(file_names):\n",
        "    # Construct the full path to the image file\n",
        "    img_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # Load the image with the right target size for your model\n",
        "    img = image.load_img(img_path, target_size=(256, 256))  # resize to smaller size\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Normalize the image array (if required)\n",
        "    img_array /= 255.0  # example normalization\n",
        "\n",
        "    # Add a batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Predict the image\n",
        "    predictions = modelV.predict(img_array)\n",
        "\n",
        "    # Get the predicted class index and corresponding confidence probability\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    confidence = np.max(predictions)\n",
        "\n",
        "    # Plot the image and predicted title in a subplot\n",
        "    col = i // num_images_per_col\n",
        "    row = i % num_images_per_col\n",
        "    ax = axes[row, col]\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f\"{getcode(predicted_class_index)}\\nConfidence: {confidence:.2f}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "# Adjust layout and display the subplots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekYr3NNzwcsB"
      },
      "source": [
        " # Estimated Weights for Each Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2778
        },
        "id": "DXjY1UtYwcsE",
        "outputId": "e8c8852d-946b-4e18-8269-f321cd8a37d1"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Cardboard\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:  # Limit to first 10 images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        "    # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    print(f\"Estimated weight of object in Kg {image_file}:\", object_weight_kg)\n",
        "\n",
        "\n",
        "\n",
        "    # Display the original image and the edges side by side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(121), plt.imshow(image, cmap='gray')\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122), plt.imshow(edges, cmap='gray')\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TnO_HDv8wcsE",
        "outputId": "f2e7157a-5ebf-4e2a-a789-67230ccf40b3"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Cardboard\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "# Initialize a variable to store the total weight of all images\n",
        "total_weight = 0\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:]:  # Process all images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        "\n",
        "    # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    print(f\"Estimated weight of object in Kg {image_file}:\", object_weight_kg)\n",
        "\n",
        "\n",
        "    # Add the edge weight to the total weight\n",
        "    total_weight += object_weight_kg\n",
        "\n",
        "    print(f\"Weight of edge pixels in {image_file}:\", object_weight_kg)\n",
        "\n",
        "# Print the total weight of all images\n",
        "print(\"Total weight of Cardboard class\", total_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2758
        },
        "id": "s0OLq8vywcsE",
        "outputId": "4108755b-b43e-470a-ca5e-23d70f80c017"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Glass\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:  # Limit to first 10 images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        "\n",
        "   # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    print(f\"Estimated weight of object in Kg {image_file}:\", object_weight_kg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Display the original image and the edges side by side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(121), plt.imshow(image, cmap='gray')\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122), plt.imshow(edges, cmap='gray')\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2758
        },
        "id": "tEfmEP4LwcsF",
        "outputId": "56888ce8-4a06-45ef-a2d0-003d38492017"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Paper\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:  # Limit to first 10 images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        "\n",
        " # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    print(f\"Estimated weight of object in Kg {image_file}:\", object_weight_kg)\n",
        "\n",
        "    # Display the original image and the edges side by side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(121), plt.imshow(image, cmap='gray')\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122), plt.imshow(edges, cmap='gray')\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QconDbeHwcsG",
        "outputId": "fbaafad6-7689-4c53-b5e3-5c4ad8e15b4f"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Paper\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "\n",
        "# Initialize a variable to store the total weight of all images\n",
        "total_weight = 0\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "# Process each image file\n",
        "for image_file in image_files[:]:  # Process all images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        " # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    print(f\"Estimated weight of object in Kg {image_file}:\", object_weight_kg)\n",
        "\n",
        "\n",
        "    # Add the edge weight to the total weight\n",
        "    total_weight += object_weight_kg\n",
        "\n",
        "    print(f\"Weight of edge pixels in {image_file}:\", object_weight_kg)\n",
        "\n",
        "# Print the total weight of all images\n",
        "print(\"Total weight of paper class\", total_weight)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2778
        },
        "id": "p2PBGpzLwcsG",
        "outputId": "171b7d49-25fa-405a-e485-6e118dcf2cee"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Vegetation\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:  # Limit to first 10 images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        "\n",
        "    # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    print(f\"Estimated weight of object in Kg {image_file}:\", object_weight_kg)\n",
        "\n",
        "\n",
        "\n",
        "    # Display the original image and the edges side by side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(121), plt.imshow(image, cmap='gray')\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122), plt.imshow(edges, cmap='gray')\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R11xxiBnwcsG",
        "outputId": "fac7c737-33cf-4127-fdb5-299074035205"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Vegetation\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Define the lower and upper threshold for Canny edge detection\n",
        "lower = 50\n",
        "upper = 150\n",
        "\n",
        "# Define the kernel size for Gaussian blurring\n",
        "kernel_size = 5\n",
        "pixel_to_kg_conversion_factor = 0.0001\n",
        "# Initialize a variable to store the total weight of all images\n",
        "total_weight = 0\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:]:  # Process all images\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred, lower, upper)\n",
        "        # Find contours in the edge-detected image\n",
        "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by area and select the largest contour\n",
        "    largest_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
        "\n",
        "    # Calculate the area of the largest contour\n",
        "    contour_area = cv2.contourArea(largest_contour)\n",
        "\n",
        "    # Calculate the weight of the object using the area and the conversion factor\n",
        "    object_weight_kg = contour_area * pixel_to_kg_conversion_factor\n",
        "\n",
        "    # Add the object weight to the total weight\n",
        "    total_weight+= object_weight_kg\n",
        "\n",
        "    print(f\"Estimated weight of object in {image_file}:\", object_weight_kg)\n",
        "\n",
        "# Print the total weight of all objects in all images\n",
        "print(\"Total estimated weight of Vegetation class in Kg:\", total_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsy2kp26wcsH",
        "outputId": "0cb01bc5-cdd5-4ce6-eebf-efaa2ebe2400"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the class\n",
        "class_name = \"paper\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Use the mask to separate the foreground from the background\n",
        "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
        "    background = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
        "\n",
        "    # Display the original image, the foreground, and the background side by side\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(131), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(132), plt.imshow(cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Foreground'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(133), plt.imshow(cv2.cvtColor(background, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Background'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19BSSu6hwcsH",
        "outputId": "40507366-d6ef-4844-e5e1-304bc4e77a0c"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the class\n",
        "class_name = \"Paper\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Calibration factor: weight per pixel in kilograms\n",
        "weight_per_pixel = 0.001  # Example value, replace with your calibration data\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Initialize a variable to store the total weight\n",
        "total_pixel_weight = 0\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Calculate the weight for the foreground in pixels\n",
        "    foreground_pixel_weight = cv2.countNonZero(mask)\n",
        "\n",
        "    # Update the total pixel weight\n",
        "    total_pixel_weight += foreground_pixel_weight\n",
        "\n",
        "# Convert the total pixel weight to kilograms\n",
        "total_weight_kg = total_pixel_weight * weight_per_pixel\n",
        "\n",
        "# Print the total weight in kilograms\n",
        "print(\"Total weight of all images in class paper:\", total_weight_kg, \"kg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySZRg5LYwcsI",
        "outputId": "7d2d8eeb-6a93-4d15-8b36-68a3f62d0da8"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Cardboard\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = \"Project7\"\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Use the mask to separate the foreground from the background\n",
        "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
        "    background = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
        "\n",
        "    # Display the original image, the foreground, and the background side by side\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(131), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(132), plt.imshow(cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Foreground'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(133), plt.imshow(cv2.cvtColor(background, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Background'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvyqA8MywcsI",
        "outputId": "79d7c8fb-d464-417e-c35a-df19caae030b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the class\n",
        "class_name = \"Cardboard\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Calibration factor: weight per pixel in kilograms (example value, replace with your calibration data)\n",
        "weight_per_pixel = 0.001  # Adjust this value based on your actual calibration\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Initialize a variable to store the total weight\n",
        "total_pixel_weight = 0\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Calculate the weight for the foreground in pixels\n",
        "    foreground_pixel_weight = cv2.countNonZero(mask)\n",
        "\n",
        "    # Update the total pixel weight\n",
        "    total_pixel_weight += foreground_pixel_weight\n",
        "\n",
        "# Convert the total pixel weight to kilograms\n",
        "total_weight_kg = total_pixel_weight * weight_per_pixel\n",
        "\n",
        "# Print the total weight in kilograms\n",
        "print(\"Total weight of all images in class Cardboard:\", total_weight_kg, \"kg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ogntRX5wcsI",
        "outputId": "e87fa687-dfcf-446c-a976-99f746025918"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Vegetation\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Use the mask to separate the foreground from the background\n",
        "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
        "    background = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
        "\n",
        "    # Display the original image, the foreground, and the background side by side\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(131), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(132), plt.imshow(cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Foreground'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(133), plt.imshow(cv2.cvtColor(background, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Background'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg2YXeYFwcsJ",
        "outputId": "20dc1314-b099-486a-b69f-216d96ff5304"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the class\n",
        "class_name = \"Vegetation\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Calibration factor: weight per pixel in kilograms (example value, replace with your calibration data)\n",
        "weight_per_pixel = 0.001  # Adjust this value based on your actual calibration\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Initialize a variable to store the total weight\n",
        "total_pixel_weight = 0\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Calculate the weight for the foreground in pixels\n",
        "    foreground_pixel_weight = cv2.countNonZero(mask)\n",
        "\n",
        "    # Update the total pixel weight\n",
        "    total_pixel_weight += foreground_pixel_weight\n",
        "\n",
        "# Convert the total pixel weight to kilograms\n",
        "total_weight_kg = total_pixel_weight * weight_per_pixel\n",
        "\n",
        "# Print the total weight in kilograms\n",
        "print(\"Total weight of all images in vegetation Cardboard:\", total_weight_kg, \"kg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWCohlOAwcsJ",
        "outputId": "7db13e32-964d-4975-cbbe-cb0e3fa6417b"
      },
      "outputs": [],
      "source": [
        "# Define the class\n",
        "class_name = \"Glass\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files[:10]:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Use the mask to separate the foreground from the background\n",
        "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
        "    background = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
        "\n",
        "    # Display the original image, the foreground, and the background side by side\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(131), plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(132), plt.imshow(cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Foreground'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(133), plt.imshow(cv2.cvtColor(background, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Background'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bgWwXMFwcsJ",
        "outputId": "3da9feb1-4c9d-4619-b7ae-e6c8e28c60b8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the class\n",
        "class_name = \"Glass\"\n",
        "\n",
        "# Define the directory where the images are stored\n",
        "directory = 'Project7'\n",
        "\n",
        "# Calibration factor: weight per pixel in kilograms (example value, replace with your calibration data)\n",
        "weight_per_pixel = 0.001  # Adjust this value based on your actual calibration\n",
        "\n",
        "# Get the list of image files for this class\n",
        "image_files = os.listdir(os.path.join(directory, class_name))\n",
        "\n",
        "# Initialize a variable to store the total weight\n",
        "total_pixel_weight = 0\n",
        "\n",
        "# Process each image file\n",
        "for image_file in image_files:\n",
        "    # Load the image\n",
        "    image = cv2.imread(os.path.join(directory, class_name, image_file))\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary mask\n",
        "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Calculate the weight for the foreground in pixels\n",
        "    foreground_pixel_weight = cv2.countNonZero(mask)\n",
        "\n",
        "    # Update the total pixel weight\n",
        "    total_pixel_weight += foreground_pixel_weight\n",
        "\n",
        "# Convert the total pixel weight to kilograms\n",
        "total_weight_kg = total_pixel_weight * weight_per_pixel\n",
        "\n",
        "# Print the total weight in kilograms\n",
        "print(\"Total weight of all images in class Glass:\", total_weight_kg, \"kg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3QouXkUTsdV"
      },
      "source": [
        "# Thank You"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
